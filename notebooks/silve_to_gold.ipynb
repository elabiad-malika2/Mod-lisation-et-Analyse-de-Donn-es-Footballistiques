{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34141dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Players shape: (702, 17)\n",
      "Matches shape: (488, 18)\n",
      "Teams shape: (20, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === Paths ===\n",
    "base_dir = \"../Data/Silver\"      # Folder where each team has its own subfolder\n",
    "all_dir = \"../Data/All\"\n",
    "os.makedirs(all_dir, exist_ok=True)\n",
    "\n",
    "all_players = []\n",
    "all_matches = []\n",
    "teams = []\n",
    "\n",
    "# === Loop through team folders ===\n",
    "for team_name in os.listdir(base_dir):\n",
    "    team_folder = os.path.join(base_dir, team_name)\n",
    "    if not os.path.isdir(team_folder):\n",
    "        continue\n",
    "\n",
    "    # Save team info\n",
    "    teams.append({\"team_name\": team_name})\n",
    "\n",
    "    players_path = os.path.join(team_folder, \"players_cleaned.csv\")\n",
    "    matches_path = os.path.join(team_folder, \"matches_cleaned.csv\")\n",
    "\n",
    "    if os.path.exists(players_path):\n",
    "        players_df = pd.read_csv(players_path)\n",
    "        players_df[\"team_name\"] = team_name\n",
    "        all_players.append(players_df)\n",
    "\n",
    "    \n",
    "    if os.path.exists(matches_path):\n",
    "        matches_df = pd.read_csv(matches_path)\n",
    "    \n",
    "        #  Keep only 'Home' matches to avoid duplicates\n",
    "        if \"Venue\" in matches_df.columns:\n",
    "            matches_df = matches_df[matches_df[\"Venue\"].str.lower().eq(\"home\")]\n",
    "        # Add team name (for reference)\n",
    "        matches_df[\"team_name\"] = team_name\n",
    "    \n",
    "        all_matches.append(matches_df)\n",
    "\n",
    "\n",
    "# === Concatenate ===\n",
    "all_players_df = pd.concat(all_players, ignore_index=True)\n",
    "all_matches_df = pd.concat(all_matches, ignore_index=True)\n",
    "\n",
    "# === Create Teams DataFrame ===\n",
    "teams_df = pd.DataFrame(teams).drop_duplicates().reset_index(drop=True)\n",
    "teams_df.insert(0, \"team_id\", range(1, len(teams_df) + 1))\n",
    "\n",
    "print(f\"Players shape: {all_players_df.shape}\")\n",
    "print(f\"Matches shape: {all_matches_df.shape}\")\n",
    "print(f\"Teams shape: {teams_df.shape}\")\n",
    "\n",
    "# === Optional: save for the ready phase ===\n",
    "all_players_df.to_csv(os.path.join(all_dir, \"all_players.csv\"), index=False)\n",
    "all_matches_df.to_csv(os.path.join(all_dir, \"all_matches.csv\"), index=False)\n",
    "teams_df.to_csv(os.path.join(all_dir, \"teams.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4315b946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All relational DataFrames successfully created and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# === Charger data ===\n",
    "all_players_df = pd.read_csv(os.path.join(all_dir, \"all_players.csv\"))\n",
    "all_matches_df = pd.read_csv(os.path.join(all_dir, \"all_matches.csv\"))\n",
    "teams_df = pd.read_csv(os.path.join(all_dir, \"teams.csv\"))\n",
    "\n",
    "# 1️⃣  SAISON TABLE\n",
    "\n",
    "saison_df = pd.DataFrame([{\"saison_id\": 1, \"year\": \"2024-2025\"}])\n",
    "\n",
    "# 2️⃣  COMPETITION TABLE\n",
    "\n",
    "competition_names = all_matches_df[\"Comp\"].dropna().unique()\n",
    "competition_df = pd.DataFrame({\n",
    "    \"competition_id\": range(1, len(competition_names) + 1),\n",
    "    \"competition_name\": competition_names\n",
    "})\n",
    "\n",
    "# 3️ TEAM TABLE (link to saison and competition)\n",
    "# Assume all teams play in the same competition & season\n",
    "teams_df[\"saison_id\"] = 1\n",
    "\n",
    "# 4️⃣  PLAYER + PLAYER_STATISTICS TABLES\n",
    "# Player identity\n",
    "player_df = all_players_df[[\"Player\", \"Nation\", \"Age\", \"Pos\", \"team_name\"]].drop_duplicates()\n",
    "player_df = player_df.merge(teams_df[[\"team_id\", \"team_name\"]], on=\"team_name\", how=\"left\")\n",
    "player_df.insert(0, \"player_id\", range(1, len(player_df) + 1))\n",
    "player_df.drop(columns=[\"team_name\"], inplace=True)\n",
    "\n",
    "# Player statistics (aggregate-level, not per match)\n",
    "stat_cols = [c for c in all_players_df.columns if c not in [\"Player\", \"Nation\", \"Age\", \"Pos\", \"team_name\"]]\n",
    "player_statistics_df = all_players_df.merge(\n",
    "    player_df[[\"player_id\", \"Player\"]], on=\"Player\", how=\"left\"\n",
    ")[[\"player_id\"] + stat_cols]\n",
    "\n",
    "\n",
    "\n",
    "# 5️⃣ MATCH TABLE\n",
    "# Create match table using only the \"Home\" matches we kept earlier\n",
    "\n",
    "match_df = all_matches_df.copy()\n",
    "\n",
    "# Merge to get the team_id for the main team (the one whose folder we scraped)\n",
    "match_df = match_df.merge(\n",
    "    teams_df[[\"team_id\", \"team_name\"]],\n",
    "    on=\"team_name\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Clean and map opponent name to team_id (if opponent exists in teams_df)\n",
    "match_df[\"Opponent\"] = match_df[\"Opponent\"].astype(str).str.strip()\n",
    "match_df = match_df.merge(\n",
    "    teams_df.rename(columns={\"team_id\": \"opponent_id\", \"team_name\": \"Opponent\"}),\n",
    "    on=\"Opponent\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Create match_id\n",
    "match_df.insert(0, \"match_id\", range(1, len(match_df) + 1))\n",
    "\n",
    "# Standardize attendance (remove commas and cast to int)\n",
    "if \"Attendance\" in match_df.columns:\n",
    "    match_df[\"Attendance\"] = (\n",
    "        match_df[\"Attendance\"].astype(str).str.replace(\",\", \"\", regex=False).replace(\"\", None)\n",
    "    )\n",
    "    match_df[\"Attendance\"] = pd.to_numeric(match_df[\"Attendance\"], errors=\"coerce\")\n",
    "\n",
    "# Assign saison and competition (for now we assume single season & competition)\n",
    "match_df[\"saison_id\"] = 1\n",
    "match_df[\"competition_id\"] = 1\n",
    "\n",
    "# Select columns relevant to the 'match' table\n",
    "match_cols = [\n",
    "    \"match_id\", \"team_id\", \"opponent_id\", \"datetime\",\n",
    "    \"Attendance\", \"Referee\", \"saison_id\", \"competition_id\"\n",
    "]\n",
    "match_df = match_df[match_cols]\n",
    "\n",
    "# 6️⃣ MATCH RESULT TABLE\n",
    "# Each match_id has its result stats (GF, GA, etc.)\n",
    "\n",
    "match_result_df = all_matches_df.copy()\n",
    "\n",
    "# Merge with match_df to get the match_id for each row\n",
    "match_result_df = match_result_df.merge(\n",
    "    teams_df[[\"team_id\", \"team_name\"]],\n",
    "    on=\"team_name\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "match_result_df = match_result_df.merge(\n",
    "    match_df[[\"match_id\", \"datetime\", \"team_id\"]],\n",
    "    on=[\"datetime\", \"team_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Keep relevant result columns\n",
    "result_cols = [\"match_id\", \"GF\", \"GA\", \"Result\", \"xG\", \"xGA\"]\n",
    "match_result_df = match_result_df[result_cols].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#  SAVE ALL TABLES\n",
    "\n",
    "glod_dir = \"../Data/Gold\"\n",
    "\n",
    "\n",
    "saison_df.to_csv(os.path.join(glod_dir, \"saison.csv\"), index=False)\n",
    "competition_df.to_csv(os.path.join(glod_dir, \"competition.csv\"), index=False)\n",
    "teams_df.to_csv(os.path.join(glod_dir, \"team.csv\"), index=False)\n",
    "player_df.to_csv(os.path.join(glod_dir, \"player.csv\"), index=False)\n",
    "player_statistics_df.to_csv(os.path.join(glod_dir, \"player_statistics.csv\"), index=False)\n",
    "match_df.to_csv(os.path.join(glod_dir, \"match.csv\"), index=False)\n",
    "match_result_df.to_csv(os.path.join(glod_dir, \"match_result.csv\"), index=False)\n",
    "\n",
    "print(\"All relational DataFrames successfully created and saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
